人工神经网络中一层的前向传播运算就是一次2维矩阵相乘。神经网络涉及的2维矩阵运算可以用 ``input[1,参数数量]`` 表示输入，``output[1,结果数量]``表示输出结果。``W[参数数量,结果数量]`` 表示权重。

一个大矩阵可以近似表示成两个小矩阵相乘的结果。所以，在
```math
output = input \cdot W
```
中输入是变化的，但$W$是固定的，所以，可以将$W$拆解成两个小矩阵$A$和$B$，那么就变成了
```math
output \approx input \cdot A \cdot B
```

其中A和B的尺寸远远小于W。其中A的形状[参数数量,秩]，B的形状[秩,结果数量]